{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a34017a6-09c9-47fc-80f4-f2df09d80a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "69927003-6546-4499-ae6b-f4895bf8a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(fn): \n",
    "    with open(fn, \"r\") as f: \n",
    "        d = json.loads(f.read())\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6b690f9e-7ca8-4ee2-a0e8-4ce91ee2b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = {\n",
    "    \"step1\": [4, 7, 9, 11, 18, 21, 30, 32, 34, 36, 40, 42, 44, 47, 53, 56, 62, 68, 77, 80, 85, 88, 89, 100, 105, 113, 114],\n",
    "    \"step2\": [25, 26, 33, 53, 60, 76, 80, 87, 107, 114],\n",
    "    \"step3\": [5, 21, 34, 41, 63, 66, 67, 88, 96, 102, 113, 118, 130]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "add054c6-80a1-4e53-aab7-7263d703c984",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_models = [\n",
    "    \"llama-7b-hf\",\n",
    "    \"alpaca-lora\",\n",
    "    \"medalapca-7b\",\n",
    "    \"medalapca-lora-7b-8bit\",\n",
    "    \"medalapca-lora-13b-8bit\",\n",
    "    \"medalapca-lora-30b-8bit\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0ed99abc-5e4e-4913-b236-e12973049cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(eval_results): \n",
    "    acc = {model: {\"step1\": [], \"step2\": [], \"step3\": []} for model in available_models}\n",
    "    for model, results in eval_results.items(): \n",
    "        for step, answers in results.items(): \n",
    "            acc[model][step] = np.mean(answers)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "860b2666-0e06-44f3-bdfa-964abe47f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = {model: {\"step1\": [], \"step2\": [], \"step3\": []} for model in available_models}\n",
    "for model in available_models: \n",
    "    for s in [1,2,3]: \n",
    "        if not os.path.exists(f\"{model}-step{s}.json\"): \n",
    "            continue\n",
    "        step = load_json(f\"{model}-step{s}.json\")\n",
    "        solutions = load_json(f\"step{s}_solutions.json\")\n",
    "        for question in step: \n",
    "            if question[\"no\"] in exclude[f\"step{s}\"]: \n",
    "                continue\n",
    "            correct_option = solutions[str(question[\"no\"])]\n",
    "            eval_results[model][f\"step{s}\"].append(question.get(\"answer0\", \"\").startswith(correct_option))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3d57db63-d354-43c9-9e10-c0bf54ad1b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llama-7b-hf': {'step1': 0.17391304347826086,\n",
       "  'step2': 0.10909090909090909,\n",
       "  'step3': nan},\n",
       " 'alpaca-lora': {'step1': 0.2608695652173913,\n",
       "  'step2': 0.2636363636363636,\n",
       "  'step3': 0.2661290322580645},\n",
       " 'medalapca-7b': {'step1': 0.2608695652173913,\n",
       "  'step2': 0.3,\n",
       "  'step3': 0.3629032258064516},\n",
       " 'medalapca-lora-7b-8bit': {'step1': 0.1956521739130435,\n",
       "  'step2': 0.20909090909090908,\n",
       "  'step3': 0.08064516129032258},\n",
       " 'medalapca-lora-13b-8bit': {'step1': 0.21739130434782608,\n",
       "  'step2': 0.15454545454545454,\n",
       "  'step3': 0.23387096774193547},\n",
       " 'medalapca-lora-30b-8bit': {'step1': 0.0, 'step2': nan, 'step3': nan}}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "578e4871-8e1c-4bf0-a50e-3bfbc8332831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def md_table(data): \n",
    "    header = [f\"{'Model':25}\", 'Step1   ', 'Step2   ', 'Step3   ']\n",
    "    markdown_table = []\n",
    "\n",
    "    # Add table header\n",
    "    markdown_table.append('| ' + ' | '.join(header) + ' |')\n",
    "    markdown_table.append(f'|{\"-\"*22}' + f'{\"-\"*5}|{\"-\"*5}' * (len(header) - 1) + f'{\"-\"*5}|')\n",
    "\n",
    "    # Add table rows\n",
    "    for model, values in data.items():\n",
    "        row = [f\"{model:25}\"] + [f\"{v:.3f}   \" if not (isinstance(v, float) and np.isnan(v)) else f\"{'nan':8}\" for v in values.values()]\n",
    "        markdown_table.append('| ' + ' | '.join(row) + ' |')\n",
    "\n",
    "    # Combine markdown table lines and print\n",
    "    markdown_table_str = '\\n'.join(markdown_table)\n",
    "    print(markdown_table_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "51173cf7-db61-42a6-be60-121d1fa3807d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model                     | Step1    | Step2    | Step3    |\n",
      "|---------------------------|----------|----------|----------|\n",
      "| llama-7b-hf               | 0.174    | 0.109    | nan      |\n",
      "| alpaca-lora               | 0.261    | 0.264    | 0.266    |\n",
      "| medalapca-7b              | 0.261    | 0.300    | 0.363    |\n",
      "| medalapca-lora-7b-8bit    | 0.196    | 0.209    | 0.081    |\n",
      "| medalapca-lora-13b-8bit   | 0.217    | 0.155    | 0.234    |\n",
      "| medalapca-lora-30b-8bit   | 0.000    | nan      | nan      |\n"
     ]
    }
   ],
   "source": [
    "md_table(accuracy(eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a47128e-3087-4388-8376-7d57d3e0ca79",
   "metadata": {},
   "source": [
    "| Model                     | Step1    | Step2    | Step3    |\n",
    "|---------------------------|----------|----------|----------|\n",
    "| llama-7b-hf               | 0.174    | 0.109    | nan      |\n",
    "| alpaca naive              | 0.243    | 0.222    | 0.329    |\n",
    "| alpaca-lora               | 0.261    | 0.264    | 0.266    |\n",
    "| chatdoctor                | 0.187    | 0.185    | 0.148    |\n",
    "| medalapca-7b              | 0.261    | 0.300    | 0.363    |\n",
    "| medalapca-lora-7b-8bit    | 0.011    | nan      | nan      |\n",
    "| medalapca-lora-13b-8bit   | 0.217    | 0.155    | 0.234    |\n",
    "| medalapca-lora-30b-8bit   | 0.000    | nan      | nan      |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d7631e-7a41-4a47-8e5d-16f5f98d3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "| step  | model                     | top n accuracy      |\n",
    "|-------|---------------------------|---------------------|\n",
    "| step1 | alpaca_naive              | mean accuracy:  0.243|\n",
    "| step1 | chatdoctor                | mean accuracy:  0.187|\n",
    "| step2 | alpaca_naive              | mean accuracy:  0.222|\n",
    "| step2 | chatdoctor                | mean accuracy:  0.185|\n",
    "| step3 | alpaca_naive              | mean accuracy:  0.329|\n",
    "| step3 | chatdoctor                | mean accuracy:  0.148|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
